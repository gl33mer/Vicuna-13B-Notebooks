{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuhausmatheus/vicuna/blob/main/Vicuna_13B_PRO_GPU_RAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GNnhOCQE7sa"
      },
      "source": [
        "**You may encounter an error when installing flash-attn. I couldn't figure it out. Maybe you can.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing GPU access on Colab"
      ],
      "metadata": {
        "id": "ME-TlkbrQXic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bb87e0-3386-4802-94f6-e4b680678b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr  7 15:11:06 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Memory access on Colab"
      ],
      "metadata": {
        "id": "R_nO3jaZQhqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04546f33-3979-4ec6-9fda-e1429cd4356c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation..."
      ],
      "metadata": {
        "id": "edefq2tSQV2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MevKtB0dEw",
        "scrolled": true,
        "outputId": "f59b2dc2-99c9-42a0-c8fb-de5e05cdb322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch==1.13.1+cu116 in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision==0.14.1+cu116 in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: torchaudio==0.13.1 in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1+cu116) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1+cu116) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1+cu116) (3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mfatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mfatal: destination path 'FastChat' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mmkdir: cannot create directory ‘checkpoints’: File exists\n",
            "--2023-04-07 15:18:28--  https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl\n",
            "Resolving huggingface.co (huggingface.co)... 52.84.125.99, 52.84.125.117, 52.84.125.98, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.84.125.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/58/74/5874e8234cbcd37dd31ca486e8492d9f1370bdd04829001f53991a866851e83f/ea4c106e475c5a8971b107e7d7a4beddaf50e5e1996f2a311c0f6ad81365998b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl%3B+filename%3D%22flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl%22%3B&Expires=1681139908&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU4Lzc0LzU4NzRlODIzNGNiY2QzN2RkMzFjYTQ4NmU4NDkyZDlmMTM3MGJkZDA0ODI5MDAxZjUzOTkxYTg2Njg1MWU4M2YvZWE0YzEwNmU0NzVjNWE4OTcxYjEwN2U3ZDdhNGJlZGRhZjUwZTVlMTk5NmYyYTMxMWMwZjZhZDgxMzY1OTk4Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODExMzk5MDh9fX1dfQ__&Signature=VAjWmw6Fi3FlSaDsZid3KZfrD2h-GZOyDlrpFZs5ftV5uTdwvHtI2QUFSsrAWy66GQNs0k6Px49DFMKxqVO8ShS0P1L9SF0RXTBwZPo23QMUj4tG-TaDyj7rjRfjh1Uwu645SAlYzCLIRpRdvJl9SMIqDeJOZQldEEDNcIInfzXRkfV7ygbW5b%7E-0tnHEgvN-bZR5eY4PXd4DpdzsH780vdk4wsNANtMwAXp665C6b0%7EUggO-KRmvjptCxfzp9ECqCReZSFU-UVQD0juFPMYQlKnPEISKVaYCwLfg7LJYH4JHZkW0GtQWM6c6DZUTwYzmgxFR5jj4LZ3%7EZLomzzTtQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-04-07 15:18:28--  https://cdn-lfs.huggingface.co/repos/58/74/5874e8234cbcd37dd31ca486e8492d9f1370bdd04829001f53991a866851e83f/ea4c106e475c5a8971b107e7d7a4beddaf50e5e1996f2a311c0f6ad81365998b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl%3B+filename%3D%22flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl%22%3B&Expires=1681139908&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU4Lzc0LzU4NzRlODIzNGNiY2QzN2RkMzFjYTQ4NmU4NDkyZDlmMTM3MGJkZDA0ODI5MDAxZjUzOTkxYTg2Njg1MWU4M2YvZWE0YzEwNmU0NzVjNWE4OTcxYjEwN2U3ZDdhNGJlZGRhZjUwZTVlMTk5NmYyYTMxMWMwZjZhZDgxMzY1OTk4Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODExMzk5MDh9fX1dfQ__&Signature=VAjWmw6Fi3FlSaDsZid3KZfrD2h-GZOyDlrpFZs5ftV5uTdwvHtI2QUFSsrAWy66GQNs0k6Px49DFMKxqVO8ShS0P1L9SF0RXTBwZPo23QMUj4tG-TaDyj7rjRfjh1Uwu645SAlYzCLIRpRdvJl9SMIqDeJOZQldEEDNcIInfzXRkfV7ygbW5b%7E-0tnHEgvN-bZR5eY4PXd4DpdzsH780vdk4wsNANtMwAXp665C6b0%7EUggO-KRmvjptCxfzp9ECqCReZSFU-UVQD0juFPMYQlKnPEISKVaYCwLfg7LJYH4JHZkW0GtQWM6c6DZUTwYzmgxFR5jj4LZ3%7EZLomzzTtQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 54.230.18.124, 54.230.18.21, 54.230.18.98, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|54.230.18.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49942604 (48M) [binary/octet-stream]\n",
            "Saving to: ‘flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl.4’\n",
            "\n",
            "flash_attn-0.2.8-cp 100%[===================>]  47.63M   197MB/s    in 0.2s    \n",
            "\n",
            "2023-04-07 15:18:28 (197 MB/s) - ‘flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl.4’ saved [49942604/49942604]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from flash-attn==0.2.8) (1.13.1+cu116)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from flash-attn==0.2.8) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->flash-attn==0.2.8) (4.5.0)\n",
            "flash-attn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!cd ~\n",
        "!git clone https://github.com/huggingface/transformers.git && cd transformers && git checkout cae78c46 && pip install .\n",
        "# Install fastchat\n",
        "!pip3 install --upgrade pip\n",
        "!git clone https://github.com/lm-sys/FastChat && cd FastChat && pip install -e .\n",
        "%pip install einops\n",
        "!mkdir checkpoints\n",
        "!wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl\n",
        "%pip install flash_attn-0.2.8-cp39-cp39-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SNhHJFz-28c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26d696a-8222-43ee-eae8-de3f13dd5f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 15:18:47--  https://raw.githubusercontent.com/oobabooga/text-generation-webui/main/download-model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9424 (9.2K) [text/plain]\n",
            "Saving to: ‘download-model.py’\n",
            "\n",
            "\rdownload-model.py     0%[                    ]       0  --.-KB/s               \rdownload-model.py   100%[===================>]   9.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-07 15:18:47 (102 MB/s) - ‘download-model.py’ saved [9424/9424]\n",
            "\n",
            "--2023-04-07 15:18:47--  https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V2_unfiltered_cleaned_split.json\n",
            "Resolving huggingface.co (huggingface.co)... 52.84.125.99, 52.84.125.117, 52.84.125.98, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.84.125.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/58/74/5874e8234cbcd37dd31ca486e8492d9f1370bdd04829001f53991a866851e83f/fdce6e0f96d37c6b5c0c2b3aeb63172283bbd40818f267009e87399a59764221?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ShareGPT_V2_unfiltered_cleaned_split.json%3B+filename%3D%22ShareGPT_V2_unfiltered_cleaned_split.json%22%3B&response-content-type=application%2Fjson&Expires=1681139928&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU4Lzc0LzU4NzRlODIzNGNiY2QzN2RkMzFjYTQ4NmU4NDkyZDlmMTM3MGJkZDA0ODI5MDAxZjUzOTkxYTg2Njg1MWU4M2YvZmRjZTZlMGY5NmQzN2M2YjVjMGMyYjNhZWI2MzE3MjI4M2JiZDQwODE4ZjI2NzAwOWU4NzM5OWE1OTc2NDIyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODExMzk5Mjh9fX1dfQ__&Signature=hd%7EfUQPG7zDC4fX9qvlfxPvJhQ4Ry4CnbK8aJXdwCLvVYvkbn23yHmVC9zp8COp7Hx2E8Mc3lx1C2-rlBv8bw5lUwab7LP5ALU3oEQRikAmk0wKPF9w-HuaXHGNbu8S%7EGwt6G1dNZHqKjwe8%7E1KUuyZJSinzrwKVqwYssM8UFs8FKW0JdJvJ66MYixnh7kQIsmydQJBi4a0ybpP-01o%7Ef9JvM-ioxZ-lljWGzPECQCIzTJgHFbqLoBwFPp-lgr7Xt9c3ETq4DlbOq0ZU4n8LSnwl%7ECmo3nN10Vh0iNd939IDyQK5Q64G9Q8y0SI6Q4mb%7EWJOc9hC5%7EYfJLXbV7cTlw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-04-07 15:18:47--  https://cdn-lfs.huggingface.co/repos/58/74/5874e8234cbcd37dd31ca486e8492d9f1370bdd04829001f53991a866851e83f/fdce6e0f96d37c6b5c0c2b3aeb63172283bbd40818f267009e87399a59764221?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ShareGPT_V2_unfiltered_cleaned_split.json%3B+filename%3D%22ShareGPT_V2_unfiltered_cleaned_split.json%22%3B&response-content-type=application%2Fjson&Expires=1681139928&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU4Lzc0LzU4NzRlODIzNGNiY2QzN2RkMzFjYTQ4NmU4NDkyZDlmMTM3MGJkZDA0ODI5MDAxZjUzOTkxYTg2Njg1MWU4M2YvZmRjZTZlMGY5NmQzN2M2YjVjMGMyYjNhZWI2MzE3MjI4M2JiZDQwODE4ZjI2NzAwOWU4NzM5OWE1OTc2NDIyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODExMzk5Mjh9fX1dfQ__&Signature=hd%7EfUQPG7zDC4fX9qvlfxPvJhQ4Ry4CnbK8aJXdwCLvVYvkbn23yHmVC9zp8COp7Hx2E8Mc3lx1C2-rlBv8bw5lUwab7LP5ALU3oEQRikAmk0wKPF9w-HuaXHGNbu8S%7EGwt6G1dNZHqKjwe8%7E1KUuyZJSinzrwKVqwYssM8UFs8FKW0JdJvJ66MYixnh7kQIsmydQJBi4a0ybpP-01o%7Ef9JvM-ioxZ-lljWGzPECQCIzTJgHFbqLoBwFPp-lgr7Xt9c3ETq4DlbOq0ZU4n8LSnwl%7ECmo3nN10Vh0iNd939IDyQK5Q64G9Q8y0SI6Q4mb%7EWJOc9hC5%7EYfJLXbV7cTlw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 54.230.18.124, 54.230.18.21, 54.230.18.98, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|54.230.18.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 578051903 (551M) [application/json]\n",
            "Saving to: ‘ShareGPT_V2_unfiltered_cleaned_split.json’\n",
            "\n",
            "ShareGPT_V2_unfilte 100%[===================>] 551.27M   245MB/s    in 2.2s    \n",
            "\n",
            "2023-04-07 15:18:49 (245 MB/s) - ‘ShareGPT_V2_unfiltered_cleaned_split.json’ saved [578051903/578051903]\n",
            "\n",
            "Downloading the model to models/decapoda-research_llama-13b-hf\n",
            "100% 8.31k/8.31k [00:00<00:00, 9.83MiB/s]\n",
            "100% 427/427 [00:00<00:00, 684kiB/s]\n",
            "100% 124/124 [00:00<00:00, 187kiB/s]\n",
            "100% 952M/952M [00:09<00:00, 97.4MiB/s]\n",
            "100% 952M/952M [00:11<00:00, 82.9MiB/s]\n",
            "100% 952M/952M [00:10<00:00, 86.8MiB/s]\n",
            "100% 952M/952M [00:11<00:00, 86.0MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 104MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 95.8MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 99.4MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 101MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 100MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 102MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 102MiB/s]\n",
            "100% 952M/952M [00:08<00:00, 108MiB/s]\n",
            "100% 952M/952M [00:10<00:00, 86.7MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 105MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 102MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 104MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 100MiB/s]\n",
            "100% 952M/952M [00:10<00:00, 93.4MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 105MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 105MiB/s]\n",
            "100% 952M/952M [00:08<00:00, 107MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 101MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 101MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 103MiB/s]\n",
            "100% 952M/952M [00:10<00:00, 87.7MiB/s]\n",
            "100% 952M/952M [00:11<00:00, 86.1MiB/s]\n",
            "100% 952M/952M [00:11<00:00, 82.8MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 102MiB/s]\n",
            "100% 952M/952M [00:11<00:00, 85.7MiB/s]\n",
            "100% 952M/952M [00:10<00:00, 89.9MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 101MiB/s] \n",
            "100% 952M/952M [00:09<00:00, 101MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 105MiB/s]\n",
            "100% 952M/952M [00:09<00:00, 102MiB/s]\n",
            "100% 983M/983M [00:09<00:00, 102MiB/s] \n",
            "100% 31.8k/31.8k [00:00<00:00, 12.3MiB/s]\n",
            "100% 2.00/2.00 [00:00<00:00, 2.09kiB/s]\n",
            "100% 500k/500k [00:00<00:00, 11.2MiB/s]\n",
            "100% 141/141 [00:00<00:00, 137kiB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/oobabooga/text-generation-webui/main/download-model.py\n",
        "!mkdir models\n",
        "!wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V2_unfiltered_cleaned_split.json\n",
        "!python download-model.py decapoda-research/llama-13b-hf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIkKAeiqE7sb"
      },
      "source": [
        "**Manually edit tokenizer_config.json to: {\"bos_token\": \"\", \"eos_token\": \"\", \"model_max_length\": 2048, \"tokenizer_class\": \"LlamaTokenizer\", \"unk_token\": \"\"}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqhstv08E7sc"
      },
      "source": [
        "**Enter wandb api key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3ZeWhhnE7sc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "f115ab12-05db-40c8-e93b-d10ad8ec6c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.14.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.19.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya2NjlT7BZ2q"
      },
      "source": [
        "**8 x A100 80gb training run** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PUdb3ZY4FkK",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e936cb2-db9e-45a3-c7e2-c1b3d7af1fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "WARNING:torch.distributed.run:\n",
            "*****************************************\n",
            "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "*****************************************\n",
            "2023-04-07 15:29:09.951532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:09.952351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:10.047862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:10.240560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:11.188418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:11.415681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:11.430466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-07 15:29:11.471464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/training_args.py:1356: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead \n",
            "  warnings.warn(\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m340\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m340 \u001b[2m│   \u001b[0mtrain()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/FastChat/fastchat/train/\u001b[0m\u001b[1;33mtrain.py\u001b[0m:\u001b[94m297\u001b[0m in \u001b[92mtrain\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mtrain\u001b[0m():                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0mparser = transformers.HfArgumentParser(                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m(ModelArguments, DataArguments, TrainingArguments))            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m297 \u001b[2m│   \u001b[0mmodel_args, data_args, training_args = parser.parse_args_into_data \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   \u001b[0mmodel = transformers.LlamaForCausalLM.from_pretrained(             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args.model_name_or_path,                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   │   \u001b[0mcache_dir=training_args.cache_dir,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mhf_argparser.py\u001b[0m:\u001b[94m332\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mparse_args_into_dataclasses\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m \u001b[96mvars\u001b[0m(namespace).items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m keys:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m331 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mdelattr\u001b[0m(namespace, k)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m332 \u001b[2m│   │   │   \u001b[0mobj = dtype(**inputs)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs.append(obj)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(namespace.\u001b[91m__dict__\u001b[0m) > \u001b[94m0\u001b[0m:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# additional namespace.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m111\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1227\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__post_init__\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1226 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1227 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (get_xla_device_type(\u001b[96mself\u001b[0m.device) != \u001b[33m\"\u001b[0m\u001b[33mGPU\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.fp16 \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.fp16_full_eval)                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1230 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdevice\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m54\u001b[0m in   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m__get__\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m1652\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_setup_devices\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1649 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._n_gpu = \u001b[94m1\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1650 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1651 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type == \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1652 \u001b[2m│   │   │   \u001b[0mtorch.cuda.set_device(device)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m device                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1655 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/cuda/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m326\u001b[0m in         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mset_device\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device)                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device >= \u001b[94m0\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m326 \u001b[2m│   │   \u001b[0mtorch._C._cuda_setDevice(device)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_device_name\u001b[0m(device: Optional[_device_t] = \u001b[94mNone\u001b[0m) -> \u001b[96mstr\u001b[0m:        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: invalid device ordinal\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 7244 closing signal SIGTERM\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 7245) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 762, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 753, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "FastChat/fastchat/train/train.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "[1]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 2 (local_rank: 2)\n",
            "  exitcode  : 1 (pid: 7246)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "[2]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 3 (local_rank: 3)\n",
            "  exitcode  : 1 (pid: 7247)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "[3]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 4 (local_rank: 4)\n",
            "  exitcode  : 1 (pid: 7248)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "[4]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 5 (local_rank: 5)\n",
            "  exitcode  : 1 (pid: 7249)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "[5]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 6 (local_rank: 6)\n",
            "  exitcode  : 1 (pid: 7250)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "[6]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 7 (local_rank: 7)\n",
            "  exitcode  : 1 (pid: 7251)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2023-04-07_15:29:17\n",
            "  host      : e42de58add57\n",
            "  rank      : 1 (local_rank: 1)\n",
            "  exitcode  : 1 (pid: 7245)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1 && echo $CUDA_LAUNCH_BLOCKING && torchrun --nnodes=1 --nproc_per_node=8 --master_port=21001 \\\n",
        "    FastChat/fastchat/train/train.py \\\n",
        "    --model_name_or_path models/decapoda-research_llama-13b-hf \\\n",
        "    --data_path ShareGPT_unfiltered_cleaned_split.json \\\n",
        "    --bf16 True \\\n",
        "    --output_dir ./checkpoints \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 1200 \\\n",
        "    --save_total_limit 100 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --fsdp \"full_shard auto_wrap\" \\\n",
        "    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --lazy_preprocess True"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}